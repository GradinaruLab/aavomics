{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "\n",
    "from aavomics import database\n",
    "import scanpy\n",
    "import anndata\n",
    "import scvi\n",
    "import pandas\n",
    "\n",
    "from aavomics import aavomics\n",
    "\n",
    "from plotly import offline as plotly\n",
    "from plotly import graph_objects\n",
    "from plotly.subplots import make_subplots\n",
    "from skimage.filters import threshold_otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALIGNMENT_NAME = \"cellranger_5.0.1_gex_mm10_2020_A\"\n",
    "\n",
    "MARKER_GENES = [\n",
    "    \"Aldh1l1\",\n",
    "    \"Sox9\",\n",
    "    \"S100b\",\n",
    "    \"Cldn5\",\n",
    "    \"Slc2a1\",\n",
    "    \"Pdgfrb\",\n",
    "    \"Rgs5\",\n",
    "    \"Abcc9\",\n",
    "    \"Hba-a1\",\n",
    "    \"Hba-a2\",\n",
    "    \"Acta2\",\n",
    "    \"Myh11\",\n",
    "    \"Tagln\",\n",
    "    \"Fam180a\",\n",
    "    \"Slc6a13\",\n",
    "    \"Dcn\",\n",
    "    \"Ptgds\",\n",
    "    \"Cx3cr1\",\n",
    "    \"Tmem119\",\n",
    "    \"Itgal\",\n",
    "    \"Gzma\",\n",
    "    \"Mrc1\",\n",
    "    \"Rbfox3\",\n",
    "    \"Olig2\",\n",
    "    \"Pdgfra\",\n",
    "    \"Cspg4\",\n",
    "    \"Mog\",\n",
    "    \"Mbp\",\n",
    "    \"Ptprz1\",\n",
    "    \"Bmp4\",\n",
    "    \"Nkx2-2\",\n",
    "    \"Vcan\"\n",
    "]\n",
    "\n",
    "TAXONOMY_NAME = \"CCN202105070\"\n",
    "SEED = 1042\n",
    "CLUSTER_OBS_NAME = \"leiden_scVI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = []\n",
    "cell_set_names = []\n",
    "        \n",
    "for cell_set_index, cell_set in enumerate(database.CELL_SETS):\n",
    "    \n",
    "    print(cell_set.name)\n",
    "    \n",
    "    anndata_file_path = cell_set.get_anndata_file_path(alignment_name=ALIGNMENT_NAME)\n",
    "    \n",
    "    if not os.path.exists(anndata_file_path):\n",
    "        print(\"Missing %s, skipping\" % cell_set.name)\n",
    "        continue\n",
    "    \n",
    "    adata = anndata.read(anndata_file_path)\n",
    "    adata = adata[adata.obs[\"Cell Called\"] == \"True\"].copy()\n",
    "    \n",
    "    adatas.append(adata)\n",
    "    cell_set_names.append(cell_set.name)\n",
    "    \n",
    "merged_adata = adatas[0].concatenate(adatas[1:], batch_key=\"Cell Set\", batch_categories=numpy.array(cell_set_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_maxes = merged_adata.X.max(axis=0)\n",
    "gene_maxes = numpy.array(gene_maxes.todense()).flatten()\n",
    "gene_mask = (gene_maxes > 0)\n",
    "merged_adata = merged_adata[:, gene_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.data.setup_anndata(merged_adata, batch_key=\"Cell Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = scvi.model.SCVI(\n",
    "    merged_adata,\n",
    "    n_latent=20,\n",
    "    n_layers=2,\n",
    "    n_hidden=256\n",
    ")\n",
    "\n",
    "vae.train(\n",
    "    frequency=1,\n",
    "    n_epochs_kl_warmup=None,\n",
    "    n_iter_kl_warmup=128*5000/400, # Based on documentation at https://www.scvi-tools.org/en/stable/api/reference/scvi.core.trainers.UnsupervisedTrainer.html\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_adata.obsm[\"X_scVI\"] = vae.get_latent_representation(merged_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanpy.pp.neighbors(merged_adata, use_rep=\"X_scVI\", random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanpy.tl.leiden(merged_adata, key_added=CLUSTER_OBS_NAME, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanpy.tl.tsne(merged_adata, use_rep=\"X_scVI\", n_jobs=8, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_gene_non_zeros_df = pandas.DataFrame(index=sorted(merged_adata.obs[CLUSTER_OBS_NAME].unique().astype(numpy.uint16)), columns=merged_adata.var.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scvi import _CONSTANTS\n",
    "from scvi.core.distributions import NegativeBinomial, ZeroInflatedNegativeBinomial\n",
    "from typing import Dict, Iterable, Optional, Sequence, Union\n",
    "from anndata import AnnData\n",
    "\n",
    "from scvi.model._utils import (\n",
    "    _get_batch_code_from_category,\n",
    "    _get_var_names_from_setup_anndata,\n",
    "    scrna_raw_counts_properties,\n",
    ")\n",
    "\n",
    "@torch.no_grad()\n",
    "def posterior_predictive_sample(\n",
    "    self,\n",
    "    adata: Optional[AnnData] = None,\n",
    "    indices: Optional[Sequence[int]] = None,\n",
    "    n_samples: int = 1,\n",
    "    gene_list: Optional[Sequence[str]] = None,\n",
    "    batch_size: Optional[int] = None,\n",
    "    transform_batch: Optional[int] = None\n",
    ") -> np.ndarray:\n",
    "    r\"\"\"\n",
    "    Generate observation samples from the posterior predictive distribution.\n",
    "\n",
    "    The posterior predictive distribution is written as :math:`p(\\hat{x} \\mid x)`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata\n",
    "        AnnData object with equivalent structure to initial AnnData. If `None`, defaults to the\n",
    "        AnnData object used to initialize the model.\n",
    "    indices\n",
    "        Indices of cells in adata to use. If `None`, all cells are used.\n",
    "    n_samples\n",
    "        Number of samples for each cell.\n",
    "    gene_list\n",
    "        Names of genes of interest.\n",
    "    batch_size\n",
    "        Minibatch size for data loading into model. Defaults to `scvi.settings.batch_size`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_new : :py:class:`torch.Tensor`\n",
    "        tensor with shape (n_cells, n_genes, n_samples)\n",
    "    \"\"\"\n",
    "    if self.model.gene_likelihood not in [\"zinb\", \"nb\", \"poisson\"]:\n",
    "        raise ValueError(\"Invalid gene_likelihood.\")\n",
    "\n",
    "    adata = self._validate_anndata(adata)\n",
    "    scdl = self._make_scvi_dl(adata=adata, indices=indices, batch_size=batch_size)\n",
    "\n",
    "    if indices is None:\n",
    "        indices = np.arange(adata.n_obs)\n",
    "\n",
    "    if gene_list is None:\n",
    "        gene_mask = slice(None)\n",
    "    else:\n",
    "        all_genes = _get_var_names_from_setup_anndata(adata)\n",
    "        gene_mask = [True if gene in gene_list else False for gene in all_genes]\n",
    "\n",
    "    x_new = []\n",
    "    for tensors in scdl:\n",
    "        x = tensors[_CONSTANTS.X_KEY]\n",
    "        batch_idx = tensors[_CONSTANTS.BATCH_KEY]\n",
    "        labels = tensors[_CONSTANTS.LABELS_KEY]\n",
    "        outputs = self.model.inference(\n",
    "            x, batch_index=batch_idx, y=labels, n_samples=n_samples, transform_batch=transform_batch\n",
    "        )\n",
    "        px_r = outputs[\"px_r\"]\n",
    "        px_rate = outputs[\"px_rate\"]\n",
    "        px_dropout = outputs[\"px_dropout\"]\n",
    "\n",
    "        if self.model.gene_likelihood == \"poisson\":\n",
    "            l_train = px_rate\n",
    "            l_train = torch.clamp(l_train, max=1e8)\n",
    "            dist = torch.distributions.Poisson(\n",
    "                l_train\n",
    "            )  # Shape : (n_samples, n_cells_batch, n_genes)\n",
    "        elif self.model.gene_likelihood == \"nb\":\n",
    "            dist = NegativeBinomial(mu=px_rate, theta=px_r)\n",
    "        elif self.model.gene_likelihood == \"zinb\":\n",
    "            dist = ZeroInflatedNegativeBinomial(\n",
    "                mu=px_rate, theta=px_r, zi_logits=px_dropout\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"{} reconstruction error not handled right now\".format(\n",
    "                    self.model.gene_likelihood\n",
    "                )\n",
    "            )\n",
    "        if n_samples > 1:\n",
    "            exprs = dist.sample().permute(\n",
    "                [1, 2, 0]\n",
    "            )  # Shape : (n_cells_batch, n_genes, n_samples)\n",
    "        else:\n",
    "            exprs = dist.sample()\n",
    "\n",
    "        if gene_list is not None:\n",
    "            exprs = exprs[:, gene_mask, ...]\n",
    "\n",
    "        x_new.append(exprs.cpu())\n",
    "    x_new = torch.cat(x_new)  # Shape (n_cells, n_genes, n_samples)\n",
    "\n",
    "    return x_new.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = sorted(merged_adata.obs[CLUSTER_OBS_NAME].unique(), key=lambda x: int(x))\n",
    "\n",
    "NUM_SAMPLES = 5000\n",
    "\n",
    "batch_cluster_gene_non_zeros_dfs = {}\n",
    "\n",
    "for batch_id in merged_adata.obs[\"_scvi_batch\"].unique():\n",
    "    \n",
    "    cluster_gene_non_zeros_df = pandas.DataFrame(index=sorted(merged_adata.obs[CLUSTER_OBS_NAME].unique().astype(numpy.uint16)), columns=merged_adata.var.index)\n",
    "\n",
    "    for cluster in clusters:\n",
    "\n",
    "        print(\"Batch %i cluster %s\" % (batch_id, cluster))\n",
    "\n",
    "        adata_copy = merged_adata[merged_adata.obs[CLUSTER_OBS_NAME] == cluster].copy()\n",
    "\n",
    "        random_sample = adata_copy[numpy.random.choice(list(range(0, adata_copy.shape[0])), replace=True, size=NUM_SAMPLES)].copy()\n",
    "\n",
    "        samples = posterior_predictive_sample(vae, random_sample, n_samples=1, transform_batch=batch_id)\n",
    "\n",
    "        non_zero_counts = (samples != 0).sum(axis=0)\n",
    "\n",
    "        p_non_zeros = numpy.array(non_zero_counts/NUM_SAMPLES)\n",
    "\n",
    "        cluster_gene_non_zeros_df.loc[int(cluster), :] = p_non_zeros\n",
    "        \n",
    "    batch_cluster_gene_non_zeros_dfs[batch_id] = cluster_gene_non_zeros_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = []\n",
    "\n",
    "clusters = merged_adata.obs[CLUSTER_OBS_NAME].unique().astype(numpy.uint16)\n",
    "batches = merged_adata.obs[\"_scvi_batch\"].unique()\n",
    "\n",
    "marker_gene_cluster_batch_counts = {}\n",
    "batch_ratio_thresholds = {}\n",
    "\n",
    "for marker_gene in MARKER_GENES:\n",
    "    \n",
    "    print(len(marker_gene_cluster_batch_counts), marker_gene)\n",
    "    \n",
    "    ensembl_id = merged_adata.var.loc[merged_adata.var['Gene Name']==marker_gene].index[0]\n",
    "    \n",
    "    cluster_batch_counts = {cluster: 0 for cluster in clusters}\n",
    "\n",
    "    for batch_id in batches:\n",
    "\n",
    "        cluster_gene_non_zeros_df = pandas.DataFrame(index=sorted(clusters), columns=merged_adata.var.index)\n",
    "\n",
    "        for cluster in cluster_gene_non_zeros_df.index.values:\n",
    "            \n",
    "            cluster_gene_non_zeros_df.loc[int(cluster), :] = batch_cluster_gene_non_zeros_dfs[batch_id].loc[int(cluster)]\n",
    "\n",
    "        values = cluster_gene_non_zeros_df[ensembl_id].astype(numpy.float32).values\n",
    "\n",
    "        nan_filter = ~numpy.isnan(values)\n",
    "        values = values[nan_filter].reshape((-1, 1))\n",
    "        \n",
    "        threshold = threshold_otsu(values)\n",
    "\n",
    "        clusters_above_threshold = cluster_gene_non_zeros_df[nan_filter].index[values.flatten() > threshold]\n",
    "        \n",
    "        for cluster in clusters_above_threshold:\n",
    "            cluster_batch_counts[cluster] += 1\n",
    "            \n",
    "        marker_gene_cluster_batch_counts[ensembl_id] = cluster_batch_counts\n",
    "\n",
    "    all_counts.extend(cluster_batch_counts.values())\n",
    "\n",
    "    batch_ratio_threshold = threshold_otsu(numpy.array(list(cluster_batch_counts.values()))/len(batches))\n",
    "    batch_ratio_thresholds[ensembl_id] = batch_ratio_threshold\n",
    "\n",
    "batch_ratio_threshold = threshold_otsu(numpy.array(all_counts)/len(batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = merged_adata.obs[CLUSTER_OBS_NAME].unique().astype(numpy.uint16)\n",
    "\n",
    "marker_gene_clusters = {}\n",
    "\n",
    "for marker_gene in MARKER_GENES:\n",
    "    \n",
    "    marker_gene_clusters[marker_gene] = []\n",
    "    \n",
    "    for cluster, batch_count in marker_gene_cluster_batch_counts[marker_gene].items():\n",
    "        \n",
    "        if batch_count/len(batches) > batch_ratio_thresholds[marker_gene]:\n",
    "            marker_gene_clusters[marker_gene].append(cluster)\n",
    "    \n",
    "    print(\"%s clusters above threshold: \" % marker_gene, marker_gene_clusters[marker_gene])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_DROP = [TAXONOMY_NAME, \"c_%s\" % TAXONOMY_NAME, \"X_%s\" % TAXONOMY_NAME, \"Y_%s\" % TAXONOMY_NAME] + [\"%s_%s\" % (TAXONOMY_NAME, marker_gene) for marker_gene in MARKER_GENES]\n",
    "\n",
    "for cell_set_index, cell_set in enumerate(database.CELL_SETS):\n",
    "    \n",
    "    anndata_file_path = cell_set.get_anndata_file_path(alignment_name=ALIGNMENT_NAME)\n",
    "    \n",
    "    if not os.path.exists(anndata_file_path):\n",
    "        print(\"Missing %s, skipping\" % cell_set.name)\n",
    "        continue\n",
    "        \n",
    "    print(cell_set.name)\n",
    "    \n",
    "    adata = anndata.read(anndata_file_path)\n",
    "    \n",
    "    for column in COLUMNS_TO_DROP:\n",
    "    \n",
    "        if column in adata.obs.columns:\n",
    "            adata.obs.drop(column, axis=1, inplace=True)\n",
    "            \n",
    "    cell_set_mask = merged_adata.obs[\"Cell Set\"] == cell_set.name\n",
    "    cell_barcodes = numpy.array([\"-\".join(x.split(\"-\")[0:-1]) for x in merged_adata[cell_set_mask].obs.index.values])\n",
    "\n",
    "    adata.obs.loc[cell_barcodes, TAXONOMY_NAME] = merged_adata[cell_set_mask].obs[CLUSTER_OBS_NAME].values\n",
    "    adata.obs.loc[cell_barcodes, \"X_%s\" % TAXONOMY_NAME] = merged_adata[cell_set_mask].obsm[\"X_tsne\"][:, 0]\n",
    "    adata.obs.loc[cell_barcodes, \"Y_%s\" % TAXONOMY_NAME] = merged_adata[cell_set_mask].obsm[\"X_tsne\"][:, 1]\n",
    "\n",
    "    adata.write_h5ad(anndata_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_gene_clusters_df = pandas.DataFrame(index=marker_gene_clusters.keys(), columns=[\"Gene Name\"] + list(sorted(clusters)))\n",
    "marker_gene_clusters_df.fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in merged_adata.obs[\"leiden_scVI\"].unique():\n",
    "    \n",
    "    cluster_mask = merged_adata.obs[\"leiden_scVI\"] == cluster\n",
    "    \n",
    "    de_df = vae.differential_expression(idx1=cluster_mask, idx2=(~cluster_mask))\n",
    "    de_df[\"Gene Name\"] = merged_adata.var.loc[de_df.index.values][\"Gene Name\"]\n",
    "    de_df.to_csv(os.path.join(\"out\", \"%s_cluster_%s_de.csv\" % (TAXONOMY_NAME, cluster)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ensembl_id in marker_gene_clusters:\n",
    "    \n",
    "    gene_name = merged_adata.var.loc[ensembl_id, \"Gene Name\"]\n",
    "        \n",
    "    marker_gene_clusters_df.loc[ensembl_id, \"Gene Name\"] = gene_name\n",
    "    \n",
    "    for cluster in marker_gene_clusters[ensembl_id]:\n",
    "        \n",
    "        marker_gene_clusters_df.loc[ensembl_id, cluster] = True\n",
    "\n",
    "marker_gene_clusters_df.to_csv(os.path.join(database.DATA_PATH, \"%s_marker_gene_clusters.csv\" % TAXONOMY_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = sorted(merged_adata.obs[CLUSTER_OBS_NAME].unique(), key=lambda x: int(x))\n",
    "cluster_gene_batch_counts_df = pandas.DataFrame(index=sorted(clusters), columns=merged_adata.var.index)\n",
    "cluster_gene_batch_counts_df.fillna(0, inplace=True)\n",
    "\n",
    "batches = merged_adata.obs[\"_scvi_batch\"].unique()\n",
    "\n",
    "for batch_id in batches:\n",
    "    \n",
    "    print(batch_id)\n",
    "\n",
    "    cluster_gene_non_zeros_df = pandas.DataFrame(index=sorted(clusters), columns=merged_adata.var.index)\n",
    "    \n",
    "    for cluster in cluster_gene_non_zeros_df.index.values:\n",
    "\n",
    "        cluster_gene_non_zeros_df.loc[int(cluster), :] = batch_cluster_gene_non_zeros_dfs[batch_id].loc[int(cluster)]\n",
    "        \n",
    "    for gene_index, ensembl_id in enumerate(cluster_gene_batch_counts_df.columns):\n",
    "        \n",
    "        if gene_index % 100 == 0:\n",
    "            print(gene_index)\n",
    "        \n",
    "        values = cluster_gene_non_zeros_df[ensembl_id].astype(numpy.float32).values\n",
    "\n",
    "        nan_filter = ~numpy.isnan(values)\n",
    "        values = values[nan_filter].reshape((-1, 1))\n",
    "        \n",
    "        threshold = threshold_otsu(values)\n",
    "\n",
    "        clusters_above_threshold = cluster_gene_non_zeros_df[nan_filter].index[values.flatten() > threshold]\n",
    "        \n",
    "        for cluster in clusters_above_threshold:\n",
    "            cluster_gene_batch_counts_df.loc[str(cluster), ensembl_id] += 1\n",
    "\n",
    "batches_threshold = threshold_otsu(cluster_gene_batch_counts_df.values.flatten()/len(batches))\n",
    "\n",
    "all_gene_clusters_df = pandas.DataFrame(index=cluster_gene_batch_counts_df.columns, columns=[\"Gene Name\"] + list(cluster_gene_batch_counts_df.index.values))\n",
    "all_gene_clusters_df.fillna(False, inplace=True)\n",
    "\n",
    "for gene_index, ensembl_id in enumerate(cluster_gene_batch_counts_df.columns):\n",
    "    \n",
    "    print(gene_index, ensembl_id)\n",
    "    \n",
    "    values = cluster_gene_batch_counts_df[ensembl_id].values / len(batches)\n",
    "    \n",
    "    gene_name = merged_adata.var.loc[ensembl_id, \"Gene Name\"]\n",
    "        \n",
    "    all_gene_clusters_df.loc[ensembl_id, \"Gene Name\"] = gene_name\n",
    "    \n",
    "    clusters_above_threshold = cluster_gene_batch_counts_df[ensembl_id][values > batches_threshold].index.values\n",
    "    \n",
    "    for cluster in clusters_above_threshold:\n",
    "        \n",
    "        all_gene_clusters_df.loc[ensembl_id, cluster] = True\n",
    "\n",
    "all_gene_clusters_df.to_csv(os.path.join(database.DATA_PATH, \"%s_gene_clusters.csv\" % TAXONOMY_NAME))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
