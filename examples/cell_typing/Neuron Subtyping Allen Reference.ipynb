{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from aavomics import database\n",
    "import anndata\n",
    "import pandas\n",
    "import numpy\n",
    "import scvi\n",
    "import scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1042\n",
    "REFERENCE_DATA_FILE_PATH = os.path.join(database.DATA_PATH, \"reference_databases\", \"20200331_Allen_Cortex_Hippocampus_10X_v3\", \"barcode_transcript_counts_filtered.h5ad\")\n",
    "CELL_TYPE_MAP_FILE_PATH = os.path.join(database.DATA_PATH, \"reference_databases\", \"neuron_type_map_20210130.pkl\")\n",
    "VAE_MODEL_FILE_PATH = os.path.join(database.DATA_PATH, \"reference_databases\", \"20200331_Allen_Cortex_Hippocampus_10X_v3\", \"vae_trained\")\n",
    "TRAINED_DATA_FILE_PATH = os.path.join(database.DATA_PATH, \"reference_databases\", \"20200331_Allen_Cortex_Hippocampus_10X_v3\", \"vae_trained.h5ad\")\n",
    "SCANVI_TRAINED_DATA_FILE_PATH = os.path.join(database.DATA_PATH, \"reference_databases\", \"20200331_Allen_Cortex_Hippocampus_10X_v3\", \"scanvi_trained.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which alignment to use. Set to None to use the first available\n",
    "ALIGNMENT_NAME = \"cellranger_5.0.1_allen_premRNA\"\n",
    "LABELED_DATA_ALIGNMENT_NAME = \"cellranger_5.0.1_gex_mm10_2020_A\"\n",
    "\n",
    "TAXONOMY_NAME = \"CCN202105041\"\n",
    "NEW_TAXONOMY_NAME = \"CCN202105050\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom label\n",
    "with open(CELL_TYPE_MAP_FILE_PATH, \"rb\") as pickle_file:\n",
    "    cell_type_map = pickle.load(pickle_file)\n",
    "\n",
    "cell_type_categorical_type = pandas.CategoricalDtype(categories=[\"\"] + list(set(cell_type_map.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data = anndata.read(REFERENCE_DATA_FILE_PATH)\n",
    "\n",
    "reference_data.obs[NEW_TAXONOMY_NAME] = pandas.Series(dtype=cell_type_categorical_type)\n",
    "reference_data.obs[NEW_TAXONOMY_NAME].loc[:] = \"\"\n",
    "\n",
    "for cell_type, cell_type_label in cell_type_map.items():\n",
    "    \n",
    "    cell_type_mask = reference_data.obs[\"cell_type_alias_label\"] == cell_type\n",
    "    \n",
    "    reference_data.obs[NEW_TAXONOMY_NAME][cell_type_mask] = cell_type_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = []\n",
    "cell_set_names = []\n",
    "\n",
    "for cell_set in database.CELL_SETS:\n",
    "    \n",
    "    labelled_anndata_file_path = cell_set.get_anndata_file_path(alignment_name=LABELED_DATA_ALIGNMENT_NAME)\n",
    "    \n",
    "    if not os.path.exists(labelled_anndata_file_path):\n",
    "        print(\"Skipping %s, doesn't have anndata file\" % cell_set.name)\n",
    "        continue\n",
    "        \n",
    "    labelled_adata = anndata.read_h5ad(labelled_anndata_file_path, backed=\"r\")\n",
    "    \n",
    "    if TAXONOMY_NAME not in labelled_adata.obs.columns:\n",
    "        print(\"Skipping %s, not annotated with %s\" % (cell_set.name, TAXONOMY_NAME))\n",
    "        continue\n",
    "    \n",
    "    labelled_cell_set_adata = labelled_adata[(labelled_adata.obs[TAXONOMY_NAME] == \"Neurons\") & (labelled_adata.obs[\"Cell Called\"] == \"True\")]\n",
    "    anndata_file_path = cell_set.get_anndata_file_path(alignment_name=ALIGNMENT_NAME)\n",
    "        \n",
    "    adata = anndata.read_h5ad(anndata_file_path)\n",
    "    adata = adata[labelled_cell_set_adata.obs.index].copy()\n",
    "    adata.obs[NEW_TAXONOMY_NAME] = pandas.Series(dtype=cell_type_categorical_type)\n",
    "    adata.obs[NEW_TAXONOMY_NAME].loc[:] = \"\"\n",
    "    adata.obs[\"sample_id\"] = cell_set.name\n",
    "    \n",
    "    adatas.append(adata)\n",
    "    cell_set_names.append(cell_set.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = set([x.split(\"-\")[1] for x in reference_data.obs.index])\n",
    "sample_ids.update(cell_set_names)\n",
    "\n",
    "sample_ids_categorical_type = pandas.CategoricalDtype(categories=list(sample_ids))\n",
    "\n",
    "reference_data.obs[\"sample_id\"] = pandas.Series(dtype=sample_ids_categorical_type)\n",
    "\n",
    "for sample_id in sample_ids:\n",
    "    reference_data.obs[\"sample_id\"][reference_data.obs.index.str.endswith(sample_id)] = sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep genes where we have data from our reference dataset\n",
    "gene_maxes = reference_data.X.max(axis=0)\n",
    "gene_maxes = numpy.array(gene_maxes.todense()).flatten()\n",
    "gene_mask = (gene_maxes > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_index = 0\n",
    "\n",
    "for row in adatas[0].var.iterrows():\n",
    "    \n",
    "    ensembl_id = row[0]\n",
    "    gene_name = row[1][\"Gene Name\"]\n",
    "    \n",
    "    if reference_data.var.index[row_index] != gene_name:\n",
    "        if reference_data.var.index[row_index] != \"%s %s\" % (gene_name, ensembl_id):\n",
    "            raise ValueError(\"Gene name doesn't match for %s at index %i! Abort!\" % (gene_name, row_index))\n",
    "    \n",
    "    row_index += 1\n",
    "    \n",
    "reference_data.var = adatas[0].var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data = reference_data.concatenate(adatas)\n",
    "del adatas\n",
    "combined_data = reference_data[:, gene_mask].copy()\n",
    "del reference_data\n",
    "del adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data_mask = ~combined_data.obs[\"sample_id\"].isin(cell_set_names).values.flatten()\n",
    "combined_data.obs[NEW_TAXONOMY_NAME].loc[~reference_data_mask] = \"\"\n",
    "combined_data.obs[NEW_TAXONOMY_NAME] = combined_data.obs[NEW_TAXONOMY_NAME].astype(cell_type_categorical_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.data.setup_anndata(combined_data, batch_key=\"sample_id\", labels_key=NEW_TAXONOMY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanvi = scvi.model.SCANVI(\n",
    "    combined_data,\n",
    "    unlabeled_category=\"\",\n",
    "    n_latent=20,\n",
    "    n_layers=2,\n",
    "    n_hidden=256\n",
    ")\n",
    "\n",
    "results = scanvi.train(\n",
    "    unsupervised_trainer_kwargs={\n",
    "        \"seed\": SEED + 1\n",
    "    },\n",
    "    semisupervised_trainer_kwargs={\n",
    "        \"seed\": SEED + 2,\n",
    "        \"n_iter_kl_warmup\": 128*5000/400,\n",
    "        \"n_epochs_kl_warmup\": None\n",
    "    },\n",
    "    balanced_sampling=True,\n",
    "    frequency=1,\n",
    "    n_epochs_kl_warmup=None,\n",
    "    n_iter_kl_warmup=128*5000/400, # Based on documentation at https://www.scvi-tools.org/en/stable/api/reference/scvi.core.trainers.UnsupervisedTrainer.html\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = scanvi.trainer.classifier_trainer.train_test_validation()[1]\n",
    "test_indices = test_dataset.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = scanvi.predict(combined_data)\n",
    "prediction_scores = scanvi.predict(combined_data, soft=True)\n",
    "prediction_scores_max = prediction_scores.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %.2f%%\" % (100*(predicted_labels[test_indices][reference_data_mask[test_indices]] == combined_data[test_indices].obs[NEW_TAXONOMY_NAME][reference_data_mask[test_indices]]).sum()/reference_data_mask[test_indices].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.obs[NEW_TAXONOMY_NAME] = predicted_labels\n",
    "combined_data.obs[\"p_%s\" % NEW_TAXONOMY_NAME] = prediction_scores_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_set_index, cell_set_name in enumerate(cell_set_names):\n",
    "        \n",
    "    print(cell_set_name)\n",
    "    \n",
    "    cell_set = database.CELL_SETS_DICT[cell_set_name]\n",
    "    \n",
    "    anndata_file_path = cell_set.get_anndata_file_path(alignment_name=LABELED_DATA_ALIGNMENT_NAME)\n",
    "    \n",
    "    if not os.path.exists(anndata_file_path):\n",
    "        print(\"Missing %s, skipping\" % cell_set.name)\n",
    "        continue\n",
    "    \n",
    "    cell_set_adata = anndata.read(anndata_file_path)\n",
    "    \n",
    "    if NEW_TAXONOMY_NAME in cell_set_adata.obs.columns:\n",
    "        cell_set_adata.obs.drop(NEW_TAXONOMY_NAME, axis=1, inplace=True)\n",
    "    if \"p_%s\" % NEW_TAXONOMY_NAME in cell_set_adata.obs.columns:\n",
    "        cell_set_adata.obs.drop(\"p_%s\" % NEW_TAXONOMY_NAME, axis=1, inplace=True)\n",
    "        \n",
    "    adata_filtered = combined_data[combined_data.obs[\"sample_id\"] == cell_set_name]\n",
    "    adata_filtered.obs.index = [\"-\".join(x.split(\"-\")[0:-1]) for x in adata_filtered.obs.index]\n",
    "    cell_set_adata.obs[NEW_TAXONOMY_NAME] = adata_filtered.obs[NEW_TAXONOMY_NAME]\n",
    "    cell_set_adata.obs[\"p_%s\" % NEW_TAXONOMY_NAME] = adata_filtered.obs[\"p_%s\" % NEW_TAXONOMY_NAME]\n",
    "    \n",
    "    cell_set_adata.write_h5ad(anndata_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
